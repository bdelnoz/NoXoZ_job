######################################################################
# FULLPATH /mnt/data2_78g/Security/scripts/AI_Projects/NoXoZ_job/2_Sources/2.1_Python/main_agent.py
######################################################################
from fastapi import FastAPI, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from api.router import router as api_router

app = FastAPI(title="NoXoZ_job API", version="1.0")

# Middleware CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["https://127.0.0.1:8443"],  # HTTPS correct
    allow_methods=["*"],
    allow_headers=["*"],
)

# Inclure le router principal avec préfixe /api
app.include_router(api_router, prefix="/api")

######################################################################
# FULLPATH /mnt/data2_78g/Security/scripts/AI_Projects/NoXoZ_job/2_Sources/2.1_Python/chroma_integration.py
######################################################################
#!/usr/bin/env python3
# PATH: /mnt/data2_78g/Security/scripts/AI_Projects/NoXoZ_job/2_Sources/2.1_Python/chroma_integration.py
# Auteur: Bruno DELNOZ
# Email: bruno.delnoz@protonmail.com
# Target usage: Intégration et gestion de Chroma Vector Store pour NoXoZ_job
# Version: v2.0 – Date: 2026-02-06
# Changelog:
#   v2.0 – 2026-02-06 – Migration vers le nouveau client PersistentClient de Chroma

"""
ChromaDB Integration – NoXoZ_job (nouvelle API)

Fonctions:
- Initialisation d’un ChromaDB persistant avec PersistentClient
- Ingestion de documents multi-format
- Recherche vectorielle de documents similaires
"""

import os
from pathlib import Path
from typing import List
import chromadb
from chromadb.utils import embedding_functions

# =========================
# CONFIGURATION DES PATHS
# =========================
BASE_DIR = Path(__file__).resolve().parent.parent.parent
DATA_DIR = BASE_DIR / "3_Data"
VECTORS_DIR = DATA_DIR / "3.1_Vectors" / "chroma_link"
VECTORS_DIR.mkdir(parents=True, exist_ok=True)

# =========================
# INITIALISATION DU CLIENT CHROMA
# =========================
def init_chroma_client(persist_directory: Path = VECTORS_DIR):
    """
    Initialise le client ChromaDB persistant avec la nouvelle API
    """
    print(f"[Chroma] Initialisation du PersistentClient dans {persist_directory}")
    client = chromadb.PersistentClient(path=str(persist_directory))
    collection = client.get_or_create_collection("noxoz_documents")
    return client, collection

# =========================
# CHARGEMENT DE DOCUMENTS
# =========================
def load_document(file_path: str) -> List[str]:
    """
    Charge le contenu d’un document en texte brut
    """
    from pypdf import PdfReader
    import docx

    ext = Path(file_path).suffix.lower()
    print(f"[Chroma] Chargement du fichier {file_path} (extension: {ext})")

    if ext == ".pdf":
        reader = PdfReader(file_path)
        text = "\n".join([page.extract_text() or "" for page in reader.pages])
        return [text]
    elif ext == ".docx":
        doc = docx.Document(file_path)
        text = "\n".join([p.text for p in doc.paragraphs])
        return [text]
    elif ext in [".md", ".txt", ".json", ".xml"]:
        with open(file_path, "r", encoding="utf-8") as f:
            return [f.read()]
    else:
        raise ValueError(f"Format non supporté: {ext}")

# =========================
# INGESTION DE DOCUMENTS
# =========================
def ingest_documents(file_paths: List[str], collection):
    """
    Ajoute les documents dans la collection ChromaDB avec embeddings
    """
    embedding_fn = embedding_functions.OpenAIEmbeddingFunction(api_key="")  # remplacer par modèle local si besoin

    for idx, file_path in enumerate(file_paths, start=1):
        try:
            texts = load_document(file_path)
            ids = [f"{Path(file_path).stem}_{i}" for i in range(len(texts))]
            metadatas = [{"source": file_path} for _ in texts]
            collection.add(
                documents=texts,
                metadatas=metadatas,
                ids=ids,
                embedding_function=embedding_fn
            )
            print(f"[Chroma] Ingesté {len(texts)} documents depuis {file_path}")
        except Exception as e:
            print(f"[Chroma] Erreur ingestion {file_path}: {e}")

    print("[Chroma] Persistance du store terminée")
    collection.client.persist()

# =========================
# RECHERCHE VECTORIELLE
# =========================
def search_similar(query: str, collection, k: int = 5):
    """
    Recherche k documents les plus similaires à la query
    """
    embedding_fn = embedding_functions.OpenAIEmbeddingFunction(api_key="")  # remplacer par modèle local
    results = collection.query(
        query_texts=[query],
        n_results=k,
        include=["metadatas", "documents"],
        embedding_function=embedding_fn
    )
    documents = results['documents'][0]
    metadatas = results['metadatas'][0]
    for idx, (doc, meta) in enumerate(zip(documents, metadatas), start=1):
        print(f"Result {idx} – source: {meta['source']}\n{doc[:200]}...\n")
    return documents

# =========================
# MAIN / EXEMPLE D’UTILISATION
# =========================
if __name__ == "__main__":
    client, collection = init_chroma_client()

    # Exemple d’ingestion
    example_files = [
        str(BASE_DIR / "2.1_Python" / "examples" / "cv_example.pdf"),
        str(BASE_DIR / "2.1_Python" / "examples" / "doc_example.docx")
    ]
    ingest_documents(example_files, collection)

    # Exemple de recherche
    query = "Expérience en Python et IA"
    search_similar(query, collection, k=3)

######################################################################
# FULLPATH /mnt/data2_78g/Security/scripts/AI_Projects/NoXoZ_job/2_Sources/2.1_Python/api/monitor.py
######################################################################
# PATH: 2_Sources/Python/routers/monitor.py
from fastapi import APIRouter
from fastapi.responses import JSONResponse
import chromadb
from chromadb.config import Settings
from chromadb.utils import embedding_functions
import sqlite3
import os
import subprocess

router = APIRouter()

# --- Configs ---
CHROMA_DIR = "/mnt/data1_100g/agent_llm_local/vectors"
SQLITE_DB = "/mnt/data1_100g/agent_llm_local/metadata.db"
LOG_DIR = "./4_Logs"
LAST_PROMPT_FILE = "./7_Infos/PERMANENT_MEMORY.md"

# Chroma client
chroma_client = chromadb.Client(Settings(
    chroma_db_impl="duckdb+parquet",
    persist_directory=CHROMA_DIR
))
emb_func = embedding_functions.HuggingFaceEmbeddingFunction(
    model_name="sentence-transformers/all-MiniLM-L6-v2"
)

# --- Helpers (mêmes que dans full_monitor.py) ---
# check_chroma(), check_sqlite(), check_ollama(), get_recent_logs(), get_last_prompt()
# [Tu peux copier les fonctions directement ici]
# -------------------------------

@router.get("/monitor/full")
async def full_monitor():
    response = {
        "fastapi": {"status": "ok"},
        "chroma": check_chroma(),
        "sqlite": check_sqlite(),
        "ollama": check_ollama(),
        "logs": get_recent_logs(),
        "last_prompt": get_last_prompt()
    }
    return JSONResponse(content=response)

######################################################################
# FULLPATH /mnt/data2_78g/Security/scripts/AI_Projects/NoXoZ_job/2_Sources/2.1_Python/api/endpoints/upload.py
######################################################################
from fastapi import APIRouter, UploadFile, File
from fastapi.responses import JSONResponse
from services.ingestion import parse_and_store_file

router = APIRouter()

@router.post("/")
async def upload_file(file: UploadFile = File(...)):
    try:
        result = await parse_and_store_file(file)
        return JSONResponse({"status": "success", "filename": file.filename, "result": result})
    except Exception as e:
        return JSONResponse({"status": "error", "message": str(e)}, status_code=500)
# Endpoint health
@router.get("/health")
async def health_upload():
    return JSONResponse({"status": "ok", "endpoint": "upload"})

######################################################################
# FULLPATH /mnt/data2_78g/Security/scripts/AI_Projects/NoXoZ_job/2_Sources/2.1_Python/api/endpoints/generate.py
######################################################################
from fastapi import APIRouter, Form
from fastapi.responses import JSONResponse
from services.generation import generate_document

router = APIRouter()

@router.post("/")
def generate_doc(prompt: str = Form(...), template: str = Form("default")):
    try:
        doc_path = generate_document(prompt, template)
        return JSONResponse({"status": "success", "file_path": doc_path})
    except Exception as e:
        return JSONResponse({"status": "error", "message": str(e)}, status_code=500)
# Endpoint health
@router.get("/health")
async def health_generate():
    return JSONResponse({"status": "ok", "endpoint": "generate"})

######################################################################
# FULLPATH /mnt/data2_78g/Security/scripts/AI_Projects/NoXoZ_job/2_Sources/2.1_Python/api/endpoints/status_web.py
######################################################################
from fastapi import APIRouter, HTTPException
from fastapi.responses import HTMLResponse, JSONResponse
from pathlib import Path
import httpx

router = APIRouter()

# Base directory pour tes scripts Python
BASE_DIR = Path(__file__).resolve().parents[2]  # remonte vers 2.1_Python

# Liste des fichiers Python à surveiller
PYTHON_FILES = [
    "api/dependencies.py",
    "api/router.py",
    "api/endpoints/generate.py",
    "api/endpoints/status.py",
    "api/endpoints/upload.py",
    "chroma_integration.py",
    "main_agent.py",
    "services/generation.py",
    "services/ingestion.py",
    "services/vector_store.py",
    "temp.py",
    "test_db_huffing.py",
    "test_sentence_transfomers.py"
]

# Endpoints health à tester
HEALTH_ENDPOINTS = [
    {"name": "Generate", "url": "https://127.0.0.1:8443/api/generate/health"},
    {"name": "Upload", "url": "https://127.0.0.1:8443/api/upload/health"},
    {"name": "Status", "url": "https://127.0.0.1:8443/api/status/health"},
    {"name": "WEB Status Page THIS PAGE !!!!!!!!!", "url": "https://127.0.0.1:8443/api/monitor/health"}
]

@router.get("/web_status", response_class=HTMLResponse)
async def web_status():
    results = []
    async with httpx.AsyncClient(verify=False) as client:
        for ep in HEALTH_ENDPOINTS:
            try:
                resp = await client.get(ep["url"], timeout=3)
                if resp.status_code == 200:
                    status = "✅ OK"
                else:
                    status = f"❌ {resp.status_code}"
            except Exception as e:
                status = f"❌ Error: {str(e)}"
            results.append({"name": ep["name"], "status": status})

    # Vérification des fichiers Python
    files_status = []
    for f in PYTHON_FILES:
        file_path = BASE_DIR / f
        files_status.append({
            "name": f,
            "status": "✅ Found" if file_path.exists() else "❌ Missing"
        })

    # Générer HTML
    html = """
    <html>
    <head>
    <title>Status Python et Endpoints</title>
    <style>
        body { font-family: monospace; background:#1e1e1e; color:#f0f0f0; }
        table { border-collapse: collapse; width: 80%; margin:auto; }
        th, td { border:1px solid #888; padding:8px; text-align:left; }
        th { background:#333; }
        td { background:#222; }
        a { color: #4fc3f7; text-decoration:none; }
    </style>
    </head>
    <body>
    <h2 style="text-align:center;">Status des Endpoints Health</h2>
    <table>
    <tr><th>Endpoint</th><th>Status</th></tr>
    """
    for r in results:
        html += f"<tr><td>{r['name']}</td><td>{r['status']}</td></tr>"

    html += "</table><br><h2 style='text-align:center;'>Status des Fichiers Python</h2><table><tr><th>Fichier</th><th>Status</th><th>Voir</th></tr>"

    for f in files_status:
        link = f"/api/monitor/read_file?file_path={f['name']}"
        html += f"<tr><td>{f['name']}</td><td>{f['status']}</td><td><a href='{link}' target='_blank'>Voir</a></td></tr>"

    html += "</table></body></html>"
    return HTMLResponse(content=html)

# Endpoint pour lire un fichier Python
@router.get("/read_file", response_class=HTMLResponse)
async def read_file(file_path: str):
    full_path = BASE_DIR / file_path
    if not full_path.exists() or not full_path.suffix == ".py":
        raise HTTPException(status_code=404, detail="File not found")
    content = full_path.read_text()
    content = content.replace("<", "&lt;").replace(">", "&gt;")
    return HTMLResponse(f"<pre>{content}</pre>")

# Endpoint health
@router.get("/health")
async def health_statusweb():
    return JSONResponse({"status": "ok", "endpoint": "status"})

######################################################################
# FULLPATH /mnt/data2_78g/Security/scripts/AI_Projects/NoXoZ_job/2_Sources/2.1_Python/api/endpoints/fastapi_full_monitor.py
######################################################################
# PATH: 2_Sources/Python/fastapi_full_monitor.py
# Auteur: Bruno Delnoz
# Email: bruno.delnoz@protonmail.com
# Version: v1.0 - 2026-02-07
# Target: Full health check monitor pour NoXoZ_job affichable sur interface web

from fastapi import FastAPI
from fastapi.responses import JSONResponse
import chromadb
from chromadb.config import Settings
from chromadb.utils import embedding_functions
import sqlite3
import os
import subprocess
import json

app = FastAPI()

# -------------------------------
# CONFIG PATHS
# -------------------------------
CHROMA_DIR = "/mnt/data1_100g/agent_llm_local/vectors"
SQLITE_DB = "/mnt/data1_100g/agent_llm_local/metadata.db"
LOG_DIR = "./4_Logs"
LAST_PROMPT_FILE = "./7_Infos/PERMANENT_MEMORY.md"

# -------------------------------
# INIT CHROMA
# -------------------------------
chroma_client = chromadb.Client(Settings(
    chroma_db_impl="duckdb+parquet",
    persist_directory=CHROMA_DIR
))
emb_func = embedding_functions.HuggingFaceEmbeddingFunction(
    model_name="sentence-transformers/all-MiniLM-L6-v2"
)

# -------------------------------
# HELPERS
# -------------------------------
def check_chroma():
    try:
        collection = chroma_client.get_or_create_collection(name="health_check_collection")
        test_query = collection.query(
            query_texts=["health check"], n_results=1, embedding_function=emb_func
        )
        return {"status": "ok", "collections_count": len(chroma_client.list_collections()), "test_query": test_query}
    except Exception as e:
        return {"status": "error", "error": str(e)}

def check_sqlite():
    try:
        conn = sqlite3.connect(SQLITE_DB)
        cursor = conn.cursor()
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
        tables = [t[0] for t in cursor.fetchall()]
        conn.close()
        return {"status": "ok", "tables": tables}
    except Exception as e:
        return {"status": "error", "error": str(e)}

def check_ollama():
    try:
        # Petit ping vers Ollama local
        # À adapter selon ton endpoint local Ollama si disponible
        result = subprocess.run(["./8_Scripts/Init/check_ollama.sh"], capture_output=True, text=True)
        status = "ok" if result.returncode == 0 else "error"
        return {"status": status, "output": result.stdout.strip()}
    except Exception as e:
        return {"status": "error", "error": str(e)}

def get_recent_logs():
    try:
        logs = {}
        for f in os.listdir(LOG_DIR):
            if f.endswith(".log"):
                path = os.path.join(LOG_DIR, f)
                with open(path, "r") as file:
                    logs[f] = file.readlines()[-10:]  # Dernières 10 lignes
        return {"status": "ok", "logs": logs}
    except Exception as e:
        return {"status": "error", "error": str(e)}

def get_last_prompt():
    try:
        if os.path.exists(LAST_PROMPT_FILE):
            with open(LAST_PROMPT_FILE, "r") as f:
                lines = f.readlines()
                return {"status": "ok", "last_lines": lines[-10:]}  # Dernières 10 lignes
        else:
            return {"status": "empty", "last_lines": []}
    except Exception as e:
        return {"status": "error", "error": str(e)}

# -------------------------------
# ENDPOINT MONITOR
# -------------------------------
@app.get("/monitor/full")
async def full_monitor():
    response = {
        "fastapi": {"status": "ok"},
        "chroma": check_chroma(),
        "sqlite": check_sqlite(),
        "ollama": check_ollama(),
        "logs": get_recent_logs(),
        "last_prompt": get_last_prompt()
    }
    return JSONResponse(content=response)

######################################################################
# FULLPATH /mnt/data2_78g/Security/scripts/AI_Projects/NoXoZ_job/2_Sources/2.1_Python/api/endpoints/status.py
######################################################################
from fastapi import APIRouter
from fastapi.responses import JSONResponse
import sqlite3
from datetime import datetime
from services.vector_store import METADATA_DB

router = APIRouter()

@router.get("/")
def status():
    try:
        conn = sqlite3.connect(METADATA_DB)
        cursor = conn.cursor()
        cursor.execute("SELECT COUNT(*) FROM documents")
        count = cursor.fetchone()[0]
        conn.close()
        return JSONResponse({
            "status": "success",
            "documents_ingested": count,
            "last_checked": datetime.utcnow().isoformat()
        })
    except Exception as e:
        return JSONResponse({"status": "error", "message": str(e)}, status_code=500)
# Endpoint health
@router.get("/health")
async def health_status():
    return JSONResponse({"status": "ok", "endpoint": "status"})

######################################################################
# FULLPATH /mnt/data2_78g/Security/scripts/AI_Projects/NoXoZ_job/2_Sources/2.1_Python/api/router.py
######################################################################
from fastapi import APIRouter
from api.endpoints import generate, status, upload, status_web

router = APIRouter()
router.include_router(generate.router, prefix="/generate", tags=["Generate"])
router.include_router(status.router, prefix="/status", tags=["Status"])
router.include_router(upload.router, prefix="/upload", tags=["Upload"])
router.include_router(status_web.router, prefix="/monitor", tags=["Monitor"])

######################################################################
# FULLPATH /mnt/data2_78g/Security/scripts/AI_Projects/NoXoZ_job/2_Sources/2.1_Python/api/dependencies.py
######################################################################
# Placeholder pour dépendances FastAPI

######################################################################
# FULLPATH /mnt/data2_78g/Security/scripts/AI_Projects/NoXoZ_job/2_Sources/2.1_Python/temp.py
######################################################################
import torch

x = torch.tensor([1.0, 2.0, 3.0])
print(x * 2)

######################################################################
# FULLPATH /mnt/data2_78g/Security/scripts/AI_Projects/NoXoZ_job/2_Sources/2.1_Python/test_db_huffing.py
######################################################################
import os
import chromadb
from chromadb.config import Settings
from sentence_transformers import SentenceTransformer
from datetime import datetime, timezone


# =========================
# CONFIG (doit matcher ton env)
# =========================

CHROMA_PERSIST_DIR = os.environ.get(
    "CHROMA_PERSIST_DIR",
    "/mnt/data1_100g/agent_llm_local/vectors"
)

MODEL_PATH = os.environ.get(
    "SENTENCE_TRANSFORMERS_HOME",
    "/mnt/data1_100g/agent_llm_local/models/sentence-transformers"
)

MODEL_NAME = "all-MiniLM-L6-v2"
COLLECTION_NAME = "test_huffing"

print("CHROMA_PERSIST_DIR =", CHROMA_PERSIST_DIR)
print("MODEL_PATH =", MODEL_PATH)

# =========================
# LOAD MODEL (singleton local)
# =========================

model = SentenceTransformer(
    model_name_or_path=MODEL_NAME,
    cache_folder=MODEL_PATH
)

print("Embedding model loaded")

# =========================
# INIT CHROMA CLIENT
# =========================

client = chromadb.Client(
    Settings(
        persist_directory=CHROMA_PERSIST_DIR,
        anonymized_telemetry=False
    )
)

collection = client.get_or_create_collection(
    name=COLLECTION_NAME,
    metadata={"description": "Test huffing embeddings"}
)

print(f"Collection '{COLLECTION_NAME}' ready")

# =========================
# TEST DATA
# =========================

texts = [
    "NoXoZ est un projet d'agent LLM local.",
    "Les embeddings permettent la recherche sémantique.",
    "ChromaDB stocke des vecteurs persistants.",
    "FastAPI expose une API pour le système."
]

metadatas = [
    {"source": "manual", "idx": i, "created_at": datetime.now(timezone.utc).isoformat()}
    for i in range(len(texts))
]

ids = [f"test_{i}" for i in range(len(texts))]

# =========================
# EMBEDDING + INSERTION
# =========================

embeddings = model.encode(texts).tolist()

collection.add(
    documents=texts,
    embeddings=embeddings,
    metadatas=metadatas,
    ids=ids
)

# client.persist()

print("Documents embedded and persisted")

# =========================
# QUERY TEST
# =========================

query = "Comment fonctionne la recherche sémantique ?"
query_embedding = model.encode([query]).tolist()

results = collection.query(
    query_embeddings=query_embedding,
    n_results=3
)

print("\nQUERY:", query)
print("\nRESULTS:")
for i, doc in enumerate(results["documents"][0]):
    print(f"- {doc}")
    print(f"  metadata: {results['metadatas'][0][i]}")

print("\nTEST OK")

######################################################################
# FULLPATH /mnt/data2_78g/Security/scripts/AI_Projects/NoXoZ_job/2_Sources/2.1_Python/services/generation.py
######################################################################
from pathlib import Path
from datetime import datetime
import subprocess
from .vector_store import search_similar
from docx import Document

OUTPUT_DIR = Path(__file__).resolve().parent.parent.parent / "5_Outputs" / "DOCX"
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

def generate_document(prompt: str, template: str = "default"):
    """
    Récupère des documents similaires depuis Chroma et génère un document avec Ollama
    """
    # Recherche des documents similaires
    docs = search_similar(prompt, k=3)
    context = "\n\n".join([d["text"] for d in docs])

    # Construire le prompt complet pour Ollama
    full_prompt = f"Contexte:\n{context}\n\nPrompt:\n{prompt}"

    # Nom du fichier de sortie
    timestamp = datetime.utcnow().strftime("%Y%m%d%H%M%S")
    output_file = OUTPUT_DIR / f"Document_{template}_{timestamp}.docx"

    # Appel de Ollama (exemple avec Mistral-7B)
    result = subprocess.run(
        ["ollama", "generate", "Mistral-7B", full_prompt],
        capture_output=True,
        text=True
    )
    generated_text = result.stdout

    # Écriture dans un DOCX
    doc = Document()
    doc.add_paragraph(generated_text)
    doc.save(output_file)

    return f"Document {output_file.name} généré avec le prompt: {prompt}"

######################################################################
# FULLPATH /mnt/data2_78g/Security/scripts/AI_Projects/NoXoZ_job/2_Sources/2.1_Python/services/vector_store.py
######################################################################
#!/usr/bin/env python3
# PATH: services/vector_store.py
# Auteur: Bruno DELNOZ
# Target usage: Gestion du stockage vectoriel et métadonnées pour NoXoZ_job
# Version: v1.1 – Date: 2026-02-06

import sqlite3
from pathlib import Path
from typing import List, Dict
import chromadb
# Ancien
# from langchain.embeddings import HuggingFaceEmbeddings
# Nouveau (LangChain 1.x)
# from langchain.embeddings.huggingface import HuggingFaceEmbeddings
from langchain_community.embeddings import HuggingFaceEmbeddings
from pypdf import PdfReader
import docx

BASE_DIR = Path(__file__).resolve().parent.parent
DATA_DIR = BASE_DIR / "3_Data"
VECTORS_DIR = DATA_DIR / "3.1_Vectors" / "chroma_link"
METADATA_DB = DATA_DIR / "3.2_Metadata" / "metadata.db"
VECTORS_DIR.mkdir(parents=True, exist_ok=True)
METADATA_DB.parent.mkdir(parents=True, exist_ok=True)

def init_chroma():
    client = chromadb.PersistentClient(path=str(VECTORS_DIR))
    collection = client.get_or_create_collection("noxoz_documents")
    return client, collection

def init_sqlite():
    conn = sqlite3.connect(METADATA_DB)
    cursor = conn.cursor()
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS documents (
            id TEXT PRIMARY KEY,
            filename TEXT,
            source TEXT,
            ingestion_date TEXT
        )
    """)
    conn.commit()
    return conn, cursor

def load_file_text(file_path: str) -> List[str]:
    ext = Path(file_path).suffix.lower()
    if ext == ".pdf":
        reader = PdfReader(file_path)
        return ["\n".join([page.extract_text() or "" for page in reader.pages])]
    elif ext == ".docx":
        doc = docx.Document(file_path)
        return ["\n".join([p.text for p in doc.paragraphs])]
    elif ext in [".md", ".txt", ".json", ".xml"]:
        with open(file_path, "r", encoding="utf-8") as f:
            return [f.read()]
    else:
        raise ValueError(f"Format non supporté: {ext}")

def ingest_file(file_path: str):
    client, collection = init_chroma()
    conn, cursor = init_sqlite()

    texts = load_file_text(file_path)
    ids = [f"{Path(file_path).stem}_{i}" for i in range(len(texts))]
    metadatas = [{"source": str(file_path)} for _ in texts]

    embeddings_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

    collection.add(
        documents=texts,
        metadatas=metadatas,
        ids=ids,
        embedding_function=embeddings_model.embed_documents
    )
    collection.client.persist()

    from datetime import datetime
    now = datetime.utcnow().isoformat()
    for doc_id in ids:
        cursor.execute("""
            INSERT OR REPLACE INTO documents (id, filename, source, ingestion_date)
            VALUES (?, ?, ?, ?)
        """, (doc_id, Path(file_path).name, str(file_path), now))
    conn.commit()
    conn.close()

def search_similar(query: str, k: int = 5) -> List[Dict]:
    client, collection = init_chroma()
    embeddings_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

    results = collection.query(
        query_texts=[query],
        n_results=k,
        include=["metadatas", "documents"],
        embedding_function=embeddings_model.embed_query
    )

    docs = []
    for doc_text, meta in zip(results["documents"][0], results["metadatas"][0]):
        docs.append({"text": doc_text, "source": meta["source"]})
    return docs

######################################################################
# FULLPATH /mnt/data2_78g/Security/scripts/AI_Projects/NoXoZ_job/2_Sources/2.1_Python/services/ingestion.py
######################################################################
from fastapi import UploadFile
from pathlib import Path
import shutil
from .vector_store import ingest_file, DATA_DIR

async def parse_and_store_file(file: UploadFile):
    """
    Sauvegarde le fichier uploadé et l'ingère dans Chroma + SQLite
    """
    # Dossier temporaire pour les uploads
    upload_dir = DATA_DIR / "uploads"
    upload_dir.mkdir(parents=True, exist_ok=True)

    file_path = upload_dir / file.filename
    # Sauvegarde du fichier uploadé
    with open(file_path, "wb") as f:
        shutil.copyfileobj(file.file, f)

    # Ingestion dans Chroma + SQLite
    ingest_file(str(file_path))

    return f"Fichier {file.filename} ingéré avec succès"

######################################################################
# FULLPATH /mnt/data2_78g/Security/scripts/AI_Projects/NoXoZ_job/2_Sources/2.1_Python/test_sentence_transfomers.py
######################################################################
from sentence_transformers import SentenceTransformer

model = SentenceTransformer("all-MiniLM-L6-v2")  # ou le chemin local de ton modèle
vec = model.encode(["Ceci est un test"])
print(vec[:1])  # les 10 premières valeurs du vecteur

